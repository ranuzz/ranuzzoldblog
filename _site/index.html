<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      noobranu &middot; so noob
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>I know nothing about everything</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/">Home</a>

    

    
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/about/">About</a>
        
      
    
      
    

	<!---
    <a class="sidebar-nav-item" href="">GitHub project</a>
    <span class="sidebar-nav-item">Currently v1.0.0</span>
	-->
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2017. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">noobranu</a>
            <small>so noob</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2017/11/02/running-dynamodb/">
        Running DynamoDB - (downloadable version)
      </a>
    </h1>

    <span class="post-date">02 Nov 2017</span>

    <h2 id="setup">setup</h2>
<ul>
  <li>Ubuntu 16.04.1 LTS VirtualBox VM : Ubuntu Server</li>
  <li><a href="http://docs.aws.amazon.com/amazondynamodb/latest/gettingstartedguide/GettingStarted.Download.html">Dwonload link</a></li>
  <li>Using Python 2.7.12</li>
</ul>

<h2 id="installing-dynamodb">installing DynamoDB</h2>
<ul>
  <li>Extract the tarball</li>
  <li>run : java -Djava.library.path=./DynamoDBLocal_lib -jar DynamoDBLocal.jar -sharedDb -inMemory</li>
</ul>

<h2 id="installing-boto3">installing Boto3</h2>
<ul>
  <li>sudo apt-get install python-boto3</li>
</ul>

<h2 id="testing">Testing</h2>
<ul>
  <li>running example <a href="http://docs.aws.amazon.com/amazondynamodb/latest/gettingstartedguide/GettingStarted.Python.01.html">MoviesCreateTable.py</a></li>
</ul>

<blockquote>
  <p>script will through follwing error without a valid AWS credential &lt;/br&gt;
botocore.exceptions.NoCredentialsError: Unable to locate credentials</p>
</blockquote>

<h3 id="creating-an-aws-credential-file">creating an AWS credential file</h3>
<ul>
  <li><a href="http://boto3.readthedocs.io/en/latest/guide/quickstart.html">Quick link</a></li>
  <li>save it in ~/.aws/credentials</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>[default]
aws_access_key_id = &lt;KEY&gt;
aws_secret_access_key = &lt;KEY&gt;
region=&lt;REGION&gt;
</code></pre>
</div>
<ul>
  <li>after this the test script should print confirmation
    <blockquote>
      <p>Table status: ACTIVE</p>
    </blockquote>
  </li>
</ul>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2017/11/02/data-analysis-notes/">
        Data Analysis Notes - Python
      </a>
    </h1>

    <span class="post-date">02 Nov 2017</span>

    <h2 id="common-terms">Common terms</h2>
<ul>
  <li><strong>mean</strong> (np.mean()): average</li>
  <li><strong>spread</strong>: A measure of how spread out the values in a distribution are</li>
  <li><strong>variance</strong> (np.var()) : A summary statistic often used to quantify spread</li>
  <li><strong>standard deviation</strong> (np.std()) : The square root of variance, also used as a measure of spread</li>
  <li><strong>mode</strong> : the value that appears most often in a set of data. <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mode.html">scipy-func</a>
    <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># mode calculation using scipy</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="n">stats</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</code></pre>
    </div>
  </li>
  <li><strong>normal distribution</strong> : An idealization of a bell-shaped distribution; also known as a Gaussian distribution</li>
  <li><strong>uniform distribution</strong>: A distribution in which all values have the same
frequency</li>
  <li><strong>tail</strong>: The part of a distribution at the high and low extremes</li>
  <li><strong>outlier</strong>: A value far from the central tendency</li>
  <li><strong>normalization</strong> : <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">wiki</a></li>
  <li><strong>PMF</strong> : Probability mass function (PMF) a representation of a distribution as a function that maps from values to probabilities. good for small dataset</li>
  <li><strong>CMF</strong> : cumulative distribution function <a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">wiki</a> , <a href="https://en.wikipedia.org/wiki/Quantile">quantile</a> , <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.quantile.html">pandas-quantile</a> , <a href="https://docs.scipy.org/doc/numpy-dev/reference/generated/numpy.percentile.html">numpy-percentile</a></li>
</ul>

<h2 id="pearsons-r">Pearson’s R</h2>
<p><a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient"><strong>wiki</strong></a></p>

<blockquote>
  <p>ranges  from -1 to 1 and represents correlation</p>
</blockquote>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># x, y are numpy array or pandas series</span>
<span class="k">def</span> <span class="nf">pearson_r</span><span class="p">(</span><span class="n">x</span> <span class="p">,</span> <span class="n">y</span><span class="p">):</span>

    <span class="c">#standardize x and y</span>
    <span class="n">xstd</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">/</span><span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    <span class="n">ystd</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">/</span><span class="n">y</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

    <span class="n">pr</span> <span class="o">=</span> <span class="p">(</span><span class="n">xstd</span><span class="o">*</span><span class="n">ystd</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">pr</span>
</code></pre>
</div>

<h2 id="effect-size">Effect size</h2>
<p><a href="https://en.wikipedia.org/wiki/Effect_size#Cohen.27s_d"><strong>wiki cohen’s d</strong></a></p>
<blockquote>
  <p>describes the size of an effect</p>
</blockquote>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">CohenEffectSize</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">group2</span><span class="p">):</span>
    <span class="s">"""Computes Cohen's effect size for two groups.
    
    group1: Series or DataFrame
    group2: Series or DataFrame
    
    returns: float if the arguments are Series;
             Series if the arguments are DataFrames
    """</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">group1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">group2</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="n">var1</span> <span class="o">=</span> <span class="n">group1</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
    <span class="n">var2</span> <span class="o">=</span> <span class="n">group2</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
    <span class="n">n1</span><span class="p">,</span> <span class="n">n2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">group1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">group2</span><span class="p">)</span>

    <span class="n">pooled_var</span> <span class="o">=</span> <span class="p">(</span><span class="n">n1</span> <span class="o">*</span> <span class="n">var1</span> <span class="o">+</span> <span class="n">n2</span> <span class="o">*</span> <span class="n">var2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">diff</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">pooled_var</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span>
    
</code></pre>
</div>

<h2 id="anlaytical-distributions">Anlaytical Distributions</h2>
<blockquote>
  <p>used to fit an empirical distribution (the distribution of actual data)</p>
  <ul>
    <li>exponential distribution</li>
    <li>normal distribution (Gaussian) : charaterstic parameters : mean and std (standard mean = 0, std = 1)</li>
    <li><a href="https://en.wikipedia.org/wiki/Normal_probability_plot">Normal probability Plot</a> : A plot of the values in a sample versus random values from a standard normal distribution. used to identify outliers, skewness, kurtosis, a need for transformations, and mixtures</li>
    <li><a href="https://en.wikipedia.org/wiki/Log-normal_distribution">log-normal distribution</a></li>
    <li><a href="https://en.wikipedia.org/wiki/Pareto_distribution">pareto distribution</a></li>
  </ul>
</blockquote>

<h2 id="pdf--probability-density-function">PDF : probability density function</h2>
<blockquote>
  <p>derivative of CDF (description?)<br />
integral of continuous PDF gives expected value
<a href="https://www.youtube.com/watch?v=Fvi9A_tEmXQ">video</a></p>
  <ul>
    <li><a href="https://en.wikipedia.org/wiki/Kernel_density_estimation">KDE</a> : is an algorithm that takes a sample and finds an appropriately smooth PDF that fits the data. use cases : visualization, Interpolation, Simulation</li>
  </ul>
</blockquote>

<p>A framework that relates representations of distribution func-
tions.
from
<img src="public/pmf_cdf_pdf.JPG" alt="PMF-CDF-PDF" /></p>

<ul>
  <li>pearson’s median skewness <a href="https://en.wikipedia.org/wiki/Skewness#Pearson.27s_second_skewness_coefficient_.28median_skewness.29">wiki</a></li>
</ul>

<blockquote>
  <p>positive, negative or zero.</p>
</blockquote>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">PearsonMedianSkewness</span><span class="p">(</span><span class="n">xs</span><span class="p">):</span>
    <span class="n">median</span> <span class="o">=</span> <span class="n">Median</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">RawMoment</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">CentralMoment</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
    <span class="n">gp</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="p">(</span><span class="n">mean</span> <span class="o">-</span> <span class="n">median</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
    <span class="k">return</span> <span class="n">gp</span>
</code></pre>
</div>

<h2 id="multivariate">Multivariate</h2>

<ul>
  <li>scatter plot : with and without jitter</li>
  <li>covariance :measure of the tendency of two variables to vary together
    <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">Cov</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">meanx</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">meany</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
  <span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">meanx</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">meanx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">meany</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">meany</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>

  <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xs</span><span class="o">-</span><span class="n">meanx</span><span class="p">,</span> <span class="n">ys</span><span class="o">-</span><span class="n">meany</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">cov</span>
</code></pre>
    </div>
  </li>
  <li>
    <p>correlation : statistic intended to quantify the strength of the relationship between two variables.
```python
def Corr(xs, ys):
  xs = np.asarray(xs)
  ys = np.asarray(ys)</p>

    <p>meanx, varx = thinkstats2.MeanVar(xs)
  meany, vary = thinkstats2.MeanVar(ys)</p>

    <p>corr = Cov(xs, ys, meanx, meany) / np.sqrt(varx * vary)
  return corr</p>
  </li>
</ul>

<p>np.corrcoef(xs, ys)</p>
<div class="highlighter-rouge"><pre class="highlight"><code>
* Pearson's correlation : defined above (Corr) : is not robust in the presence of outliers, and it tends to underestimate the strength of non-linear relationships.
* Spearman's correlation is more robust, and it can handle non-linear relationships as long as they are monotonic. Here's a function that computes Spearman's correlation
```python
import pandas as pd

def SpearmanCorr(xs, ys):
    xranks = pd.Series(xs).rank()
    yranks = pd.Series(ys).rank()
    return Corr(xranks, yranks)
</code></pre>
</div>
<ul>
  <li><a href="https://en.wikipedia.org/wiki/Correlation_and_dependence">interseting link</a> , 
<a href="https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation">one more</a></li>
</ul>

<h2 id="estimation-later-">estimation :later !!!</h2>

<h2 id="hypothesis-testing-">hypothesis testing ??</h2>

<h2 id="chi-squared-test"><a href="https://en.wikipedia.org/wiki/Chi-squared_test">chi-squared test</a></h2>

<h2 id="central-limit-theoram">central limit theoram</h2>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2017/05/09/Exploring-logistic-regression-debugging-approach/">
        Exploring logistic regression debugging approach
      </a>
    </h1>

    <span class="post-date">09 May 2017</span>

    <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># source : https://www.kaggle.com/uciml/breast-cancer-wisconsin-data</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># all imports </span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span> 
<span class="n">np</span><span class="o">.</span><span class="n">seterr</span><span class="p">(</span><span class="nb">all</span><span class="o">=</span><span class="s">'raise'</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">import</span> <span class="nn">math</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c">#helper functions</span>

<span class="k">def</span> <span class="nf">getColumn</span><span class="p">(</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">true_val</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ndarray</span><span class="p">)</span>
    <span class="n">ret_col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">m</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">ndarray</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">col</span><span class="p">]</span> <span class="o">==</span> <span class="n">true_val</span><span class="p">:</span>
            <span class="n">ret_col</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">ret_col</span>

<span class="c"># sigmoid function</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
    <span class="c">#hack</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">num</span> <span class="o">&gt;</span> <span class="mi">30</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">0.99999999999999778</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">num</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mi">500</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">9.0066236945038063e-88</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">num</span><span class="p">))</span>

<span class="n">sigmoid_v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">pow_num</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="n">ans</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">ans</span> <span class="o">=</span> <span class="n">ans</span><span class="o">*</span><span class="n">num</span>
    <span class="k">return</span> <span class="n">ans</span>

<span class="n">pow_num_v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">pow_num</span><span class="p">)</span>

<span class="c"># add one extra column per existing column for each new power</span>
<span class="k">def</span> <span class="nf">poly_all</span><span class="p">(</span><span class="n">x_features</span><span class="p">,</span> <span class="n">maxpow</span><span class="p">):</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">x_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">maxpow</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">x_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">x_features</span><span class="p">,</span> <span class="n">pow_num_v</span><span class="p">(</span><span class="n">x_features</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">p</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">x_features</span>

<span class="c"># naive cost and gradient calculation function</span>
<span class="k">def</span> <span class="nf">costFunctionBasic</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x_features</span><span class="p">,</span> <span class="n">y_result</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_result</span><span class="p">)</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">H</span> <span class="o">=</span> <span class="n">sigmoid_v</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_features</span><span class="p">,</span><span class="n">theta</span><span class="p">))</span>
    <span class="n">J</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(((</span><span class="n">y_result</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">H</span><span class="p">))</span> <span class="o">+</span> <span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">y_result</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span> <span class="n">H</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">grad</span><span class="p">)):</span>
        <span class="n">grad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">H</span> <span class="o">-</span> <span class="n">y_result</span><span class="p">)</span><span class="o">*</span><span class="n">x_features</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">J</span><span class="p">,</span> <span class="n">grad</span>

<span class="k">def</span> <span class="nf">trainPlotBasic</span><span class="p">(</span><span class="n">iterations</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x_features</span><span class="p">,</span> <span class="n">y_result</span><span class="p">):</span>
    <span class="n">jhist</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">iterx</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.001</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">iterations</span><span class="p">):</span>
        <span class="n">cost_out</span><span class="p">,</span> <span class="n">grad_out</span> <span class="o">=</span> <span class="n">costFunctionBasic</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x_features</span><span class="p">,</span> <span class="n">y_result</span><span class="p">)</span>
        <span class="n">jhist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_out</span><span class="p">)</span>
        <span class="n">iterx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">)):</span>
            <span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">grad_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">iterx</span><span class="p">,</span> <span class="n">jhist</span><span class="p">,</span> <span class="s">'rx'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">hc</span><span class="p">,</span> <span class="n">hgrad</span> <span class="o">=</span> <span class="n">costFunctionBasic</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x_features</span><span class="p">,</span> <span class="n">y_result</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">hc</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">lrCostFunctionCost</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x_features</span><span class="p">,</span> <span class="n">y_result</span><span class="p">,</span> <span class="n">lambda_val</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_result</span><span class="p">)</span>
    <span class="n">H</span> <span class="o">=</span> <span class="n">sigmoid_v</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_features</span><span class="p">,</span><span class="n">theta</span><span class="p">))</span>
    <span class="n">J</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(((</span><span class="n">y_result</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">H</span><span class="p">)</span> <span class="o">+</span> <span class="p">(((</span><span class="mi">1</span><span class="o">-</span><span class="n">y_result</span><span class="p">))</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">H</span><span class="p">))))</span>
    <span class="n">theta_ex</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">J</span> <span class="o">=</span> <span class="n">J</span> <span class="o">+</span> <span class="p">((</span><span class="n">lambda_val</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">m</span><span class="p">))</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta_ex</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">theta_ex</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">J</span>

<span class="k">def</span> <span class="nf">lrCostFunctionGrad</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x_features</span><span class="p">,</span> <span class="n">y_result</span><span class="p">,</span> <span class="n">lambda_val</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_result</span><span class="p">)</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">H</span> <span class="o">=</span> <span class="n">sigmoid_v</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_features</span><span class="p">,</span><span class="n">theta</span><span class="p">))</span>
    <span class="n">cons</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="n">lambda_val</span><span class="o">/</span><span class="n">m</span><span class="p">)</span>
    <span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(((</span><span class="n">H</span> <span class="o">-</span> <span class="n">y_result</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">x_features</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">))))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">grad</span><span class="p">)):</span>
        <span class="n">grad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">H</span> <span class="o">-</span> <span class="n">y_result</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">x_features</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
        <span class="n">g_ex</span> <span class="o">=</span>  <span class="n">cons</span> <span class="o">*</span> <span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">grad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">g_ex</span>
    <span class="k">return</span> <span class="n">grad</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">),))</span>

<span class="k">def</span> <span class="nf">lrTrain</span><span class="p">(</span><span class="n">iterations</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x_features</span><span class="p">,</span> <span class="n">y_result</span><span class="p">,</span> <span class="n">lambda_val</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">jhist</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">iterx</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">iterations</span><span class="p">):</span>
        <span class="n">cost_out</span> <span class="o">=</span> <span class="n">lrCostFunctionCost</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x_features</span><span class="p">,</span> <span class="n">y_result</span><span class="p">,</span> <span class="n">lambda_val</span><span class="p">)</span>
        <span class="n">grad_out</span> <span class="o">=</span> <span class="n">lrCostFunctionGrad</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x_features</span><span class="p">,</span> <span class="n">y_result</span><span class="p">,</span> <span class="n">lambda_val</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
        <span class="n">jhist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_out</span><span class="p">)</span>
        <span class="n">iterx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">)):</span>
            <span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">grad_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">plot</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">iterx</span><span class="p">,</span> <span class="n">jhist</span><span class="p">,</span> <span class="s">'rx'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="n">hc</span> <span class="o">=</span> <span class="n">lrCostFunctionCost</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x_features</span><span class="p">,</span> <span class="n">y_result</span><span class="p">,</span> <span class="n">lambda_val</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">hc</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">theta</span>
    
<span class="k">def</span> <span class="nf">featureNormalize</span><span class="p">(</span><span class="n">x_features</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_features</span><span class="p">)</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">x_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x_features</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">features</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">norm_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">features</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">features</span><span class="p">):</span>
        <span class="n">norm_features</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_features</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">m</span><span class="p">,))</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x_features</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">features</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
        <span class="n">norm_features</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">norm_features</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">m</span><span class="p">,))</span>
    <span class="k">return</span> <span class="n">norm_features</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">features</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span>

<span class="k">def</span> <span class="nf">featureNormalizePredefined</span><span class="p">(</span><span class="n">x_features</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_features</span><span class="p">)</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">x_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">norm_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">features</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">features</span><span class="p">):</span>
        <span class="n">norm_features</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_features</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">m</span><span class="p">,))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
        <span class="n">norm_features</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">norm_features</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">m</span><span class="p">,))</span>
    <span class="k">return</span> <span class="n">norm_features</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">features</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">learningCurve</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">Ytrain</span><span class="p">,</span> <span class="n">Xcv</span><span class="p">,</span> <span class="n">Ycv</span><span class="p">,</span> <span class="n">lambda_val</span><span class="p">,</span> <span class="n">iterations</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="n">error_train</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">error_val</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">max_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_train</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">theta_pred</span> <span class="o">=</span> <span class="n">lrTrain</span><span class="p">(</span><span class="n">iterations</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">Xtrain</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">i</span><span class="p">,],</span> <span class="n">Ytrain</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">i</span><span class="p">,],</span> <span class="n">lambda_val</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">cost_train</span> <span class="o">=</span> <span class="n">lrCostFunctionCost</span><span class="p">(</span><span class="n">theta_pred</span><span class="p">,</span> <span class="n">Xtrain</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">i</span><span class="p">,],</span> <span class="n">Ytrain</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">i</span><span class="p">,],</span> <span class="n">lambda_val</span><span class="p">)</span>
        <span class="n">cost_val</span> <span class="o">=</span> <span class="n">lrCostFunctionCost</span><span class="p">(</span><span class="n">theta_pred</span><span class="p">,</span> <span class="n">Xcv</span><span class="p">,</span> <span class="n">Ycv</span><span class="p">,</span> <span class="n">lambda_val</span><span class="p">)</span>
        <span class="n">error_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_train</span><span class="p">)</span>
        <span class="n">error_val</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_val</span><span class="p">)</span>
    <span class="n">x_axis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">error_train</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">error_train</span><span class="p">,</span> <span class="s">'r-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Learning curve for linear regression'</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Number of training examples'</span><span class="p">);</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">error_val</span><span class="p">,</span> <span class="s">'y-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">return</span>

<span class="k">def</span> <span class="nf">getcost_srm</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_actual</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">cost</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="nb">pow</span><span class="p">((</span><span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_actual</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span>

</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># data input</span>
<span class="n">data_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data.csv'</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">','</span><span class="p">)</span>
<span class="n">data_mat</span> <span class="o">=</span> <span class="n">data_df</span><span class="o">.</span><span class="n">values</span>
<span class="k">print</span><span class="p">(</span><span class="n">data_mat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>(569, 33)
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># preview</span>
<span class="n">data_df</span><span class="p">[</span><span class="mi">5</span><span class="p">:</span><span class="mi">15</span><span class="p">]</span> <span class="c">#slective  display</span>
</code></pre>
</div>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>diagnosis</th>
      <th>radius_mean</th>
      <th>texture_mean</th>
      <th>perimeter_mean</th>
      <th>area_mean</th>
      <th>smoothness_mean</th>
      <th>compactness_mean</th>
      <th>concavity_mean</th>
      <th>concave points_mean</th>
      <th>...</th>
      <th>texture_worst</th>
      <th>perimeter_worst</th>
      <th>area_worst</th>
      <th>smoothness_worst</th>
      <th>compactness_worst</th>
      <th>concavity_worst</th>
      <th>concave points_worst</th>
      <th>symmetry_worst</th>
      <th>fractal_dimension_worst</th>
      <th>Unnamed: 32</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>843786</td>
      <td>M</td>
      <td>12.45</td>
      <td>15.70</td>
      <td>82.57</td>
      <td>477.1</td>
      <td>0.12780</td>
      <td>0.17000</td>
      <td>0.15780</td>
      <td>0.08089</td>
      <td>...</td>
      <td>23.75</td>
      <td>103.40</td>
      <td>741.6</td>
      <td>0.1791</td>
      <td>0.5249</td>
      <td>0.5355</td>
      <td>0.17410</td>
      <td>0.3985</td>
      <td>0.12440</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>844359</td>
      <td>M</td>
      <td>18.25</td>
      <td>19.98</td>
      <td>119.60</td>
      <td>1040.0</td>
      <td>0.09463</td>
      <td>0.10900</td>
      <td>0.11270</td>
      <td>0.07400</td>
      <td>...</td>
      <td>27.66</td>
      <td>153.20</td>
      <td>1606.0</td>
      <td>0.1442</td>
      <td>0.2576</td>
      <td>0.3784</td>
      <td>0.19320</td>
      <td>0.3063</td>
      <td>0.08368</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>7</th>
      <td>84458202</td>
      <td>M</td>
      <td>13.71</td>
      <td>20.83</td>
      <td>90.20</td>
      <td>577.9</td>
      <td>0.11890</td>
      <td>0.16450</td>
      <td>0.09366</td>
      <td>0.05985</td>
      <td>...</td>
      <td>28.14</td>
      <td>110.60</td>
      <td>897.0</td>
      <td>0.1654</td>
      <td>0.3682</td>
      <td>0.2678</td>
      <td>0.15560</td>
      <td>0.3196</td>
      <td>0.11510</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>8</th>
      <td>844981</td>
      <td>M</td>
      <td>13.00</td>
      <td>21.82</td>
      <td>87.50</td>
      <td>519.8</td>
      <td>0.12730</td>
      <td>0.19320</td>
      <td>0.18590</td>
      <td>0.09353</td>
      <td>...</td>
      <td>30.73</td>
      <td>106.20</td>
      <td>739.3</td>
      <td>0.1703</td>
      <td>0.5401</td>
      <td>0.5390</td>
      <td>0.20600</td>
      <td>0.4378</td>
      <td>0.10720</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>9</th>
      <td>84501001</td>
      <td>M</td>
      <td>12.46</td>
      <td>24.04</td>
      <td>83.97</td>
      <td>475.9</td>
      <td>0.11860</td>
      <td>0.23960</td>
      <td>0.22730</td>
      <td>0.08543</td>
      <td>...</td>
      <td>40.68</td>
      <td>97.65</td>
      <td>711.4</td>
      <td>0.1853</td>
      <td>1.0580</td>
      <td>1.1050</td>
      <td>0.22100</td>
      <td>0.4366</td>
      <td>0.20750</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>10</th>
      <td>845636</td>
      <td>M</td>
      <td>16.02</td>
      <td>23.24</td>
      <td>102.70</td>
      <td>797.8</td>
      <td>0.08206</td>
      <td>0.06669</td>
      <td>0.03299</td>
      <td>0.03323</td>
      <td>...</td>
      <td>33.88</td>
      <td>123.80</td>
      <td>1150.0</td>
      <td>0.1181</td>
      <td>0.1551</td>
      <td>0.1459</td>
      <td>0.09975</td>
      <td>0.2948</td>
      <td>0.08452</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>11</th>
      <td>84610002</td>
      <td>M</td>
      <td>15.78</td>
      <td>17.89</td>
      <td>103.60</td>
      <td>781.0</td>
      <td>0.09710</td>
      <td>0.12920</td>
      <td>0.09954</td>
      <td>0.06606</td>
      <td>...</td>
      <td>27.28</td>
      <td>136.50</td>
      <td>1299.0</td>
      <td>0.1396</td>
      <td>0.5609</td>
      <td>0.3965</td>
      <td>0.18100</td>
      <td>0.3792</td>
      <td>0.10480</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>12</th>
      <td>846226</td>
      <td>M</td>
      <td>19.17</td>
      <td>24.80</td>
      <td>132.40</td>
      <td>1123.0</td>
      <td>0.09740</td>
      <td>0.24580</td>
      <td>0.20650</td>
      <td>0.11180</td>
      <td>...</td>
      <td>29.94</td>
      <td>151.70</td>
      <td>1332.0</td>
      <td>0.1037</td>
      <td>0.3903</td>
      <td>0.3639</td>
      <td>0.17670</td>
      <td>0.3176</td>
      <td>0.10230</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>13</th>
      <td>846381</td>
      <td>M</td>
      <td>15.85</td>
      <td>23.95</td>
      <td>103.70</td>
      <td>782.7</td>
      <td>0.08401</td>
      <td>0.10020</td>
      <td>0.09938</td>
      <td>0.05364</td>
      <td>...</td>
      <td>27.66</td>
      <td>112.00</td>
      <td>876.5</td>
      <td>0.1131</td>
      <td>0.1924</td>
      <td>0.2322</td>
      <td>0.11190</td>
      <td>0.2809</td>
      <td>0.06287</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>14</th>
      <td>84667401</td>
      <td>M</td>
      <td>13.73</td>
      <td>22.61</td>
      <td>93.60</td>
      <td>578.3</td>
      <td>0.11310</td>
      <td>0.22930</td>
      <td>0.21280</td>
      <td>0.08025</td>
      <td>...</td>
      <td>32.01</td>
      <td>108.80</td>
      <td>697.7</td>
      <td>0.1651</td>
      <td>0.7725</td>
      <td>0.6943</td>
      <td>0.22080</td>
      <td>0.3596</td>
      <td>0.14310</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 33 columns</p>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># data distribution : 60% train 20% cross validation and 20% test</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">getColumn</span><span class="p">(</span><span class="n">data_mat</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s">'M'</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="n">feature_set</span> <span class="o">=</span> <span class="n">data_mat</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">feature_set</span> <span class="o">=</span> <span class="n">feature_set</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">feature_set</span>

<span class="n">Xtrain</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">340</span><span class="p">]</span>
<span class="n">Ytrain</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">340</span><span class="p">]</span>

<span class="n">Xval</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">340</span><span class="p">:</span><span class="mi">454</span><span class="p">]</span>
<span class="n">Yval</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="mi">340</span><span class="p">:</span><span class="mi">454</span><span class="p">]</span>

<span class="n">Xtest</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">454</span><span class="p">:</span><span class="mi">569</span><span class="p">]</span>
<span class="n">Ytest</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="mi">454</span><span class="p">:</span><span class="mi">569</span><span class="p">]</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># simple gradient descent without any normalization/regularization on a linear function </span>
<span class="n">Xtrain_naive</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">),</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">Xtrain</span><span class="p">]</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Xtrain_naive</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
<span class="c"># print(costFunctionBasic(theta, Xtrain, Ytrain))</span>
<span class="c"># initial cost with simple line : 0.69314718055994529</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">trainPlotBasic</span><span class="p">(</span><span class="n">iterations</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">Xtrain_naive</span><span class="p">,</span> <span class="n">Ytrain</span><span class="p">)</span>
<span class="c"># final cost  : 17.5652032012</span>
</code></pre>
</div>

<p><img src="public/output_6_0.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>17.5652032012
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># lamda : regularization</span>
<span class="n">Xtrain_lambda</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">),</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">Xtrain</span><span class="p">]</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Xtrain_lambda</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
<span class="c">#lrCostFunctionCost(theta, Xtrain, Ytrain, 0)</span>
<span class="c">#lrCostFunctionGrad(theta, Xtrain, Ytrain, 0)</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">lambda_val</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.03</span>
<span class="n">lrTrain</span><span class="p">(</span><span class="n">iterations</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">Xtrain_lambda</span><span class="p">,</span> <span class="n">Ytrain</span><span class="p">,</span> <span class="n">lambda_val</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

<span class="c"># Cost : 2.37355571949</span>
</code></pre>
</div>

<p><img src="public/output_7_0.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>160.526793317





array([[ -1.76169066e+00],
       [ -8.05504712e+00],
       [ -1.11720283e+01],
       [ -4.75875033e+01],
       [ -3.23590072e+01],
       [ -7.79018985e-02],
       [  1.65497695e-02],
       [  9.95711315e-02],
       [  4.74403613e-02],
       [ -1.52357530e-01],
       [ -6.02914767e-02],
       [ -1.55241595e-02],
       [ -9.20818163e-01],
       [  3.57864352e-01],
       [  2.20402112e+01],
       [ -5.00831414e-03],
       [  2.51569424e-03],
       [  2.71240880e-03],
       [ -8.52539632e-04],
       [ -1.58521991e-02],
       [ -2.10039034e-03],
       [ -8.21661811e+00],
       [ -1.46369537e+01],
       [ -4.67239100e+01],
       [  3.12756286e+01],
       [ -1.00338233e-01],
       [  9.44196386e-02],
       [  1.95382645e-01],
       [  5.05882047e-02],
       [ -2.05374348e-01],
       [ -5.90371759e-02]])
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># feature normalization</span>

<span class="n">Xtrain_normalized</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">featureNormalize</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">)</span>
<span class="n">Xtrain_normalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">Xtrain_normalized</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span> <span class="n">Xtrain_normalized</span><span class="p">]</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Xtrain_normalized</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">lambda_val</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">lrTrain</span><span class="p">(</span><span class="n">iterations</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">Xtrain_normalized</span><span class="p">,</span> <span class="n">Ytrain</span><span class="p">,</span> <span class="n">lambda_val</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</code></pre>
</div>

<p><img src="public/output_8_0.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>38.6160109598





array([[  1.56672428e-01],
       [  7.59894360e-02],
       [  6.65573826e-02],
       [  6.83615375e-01],
       [ -5.05709804e-01],
       [ -6.70019838e-05],
       [  2.28785246e-03],
       [  3.35545140e-03],
       [  2.75149720e-03],
       [ -1.01283694e-03],
       [ -8.78256956e-04],
       [ -9.11205330e-03],
       [ -7.99281914e-02],
       [ -5.78977078e-02],
       [ -2.09783979e+00],
       [ -5.45545324e-04],
       [ -1.16631471e-03],
       [ -3.23362131e-03],
       [ -1.75830647e-04],
       [ -1.62198897e-03],
       [ -3.81589428e-04],
       [  1.62533141e-01],
       [  2.23532444e-01],
       [  1.32019768e+00],
       [ -3.57482442e-02],
       [  5.51544909e-04],
       [  9.06269864e-03],
       [  1.17242543e-02],
       [  6.73844320e-03],
       [  2.97136552e-04],
       [ -1.51707426e-04]])
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># higher order functions : non linear</span>

<span class="c"># helper functions</span>
<span class="k">def</span> <span class="nf">selectFeatures</span><span class="p">(</span><span class="n">x_features</span><span class="p">):</span>
    <span class="n">x_features_small</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">x_features</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_features</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>
                    <span class="n">x_features</span><span class="p">[:,</span><span class="mi">4</span><span class="p">],</span> <span class="n">x_features</span><span class="p">[:,</span><span class="mi">5</span><span class="p">],</span>
                    <span class="n">x_features</span><span class="p">[:,</span><span class="mi">6</span><span class="p">],</span> <span class="n">x_features</span><span class="p">[:,</span><span class="mi">7</span><span class="p">],</span>
                    <span class="n">x_features</span><span class="p">[:,</span><span class="mi">8</span><span class="p">],</span> <span class="n">x_features</span><span class="p">[:,</span><span class="mi">9</span><span class="p">]]</span>
    <span class="k">return</span> <span class="n">x_features_small</span>


<span class="c"># feature selection</span>
<span class="n">Xtrainsmall</span> <span class="o">=</span> <span class="n">selectFeatures</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">)</span>
<span class="n">Xtrain_normalized</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">featureNormalize</span><span class="p">(</span><span class="n">Xtrainsmall</span><span class="p">)</span>
<span class="n">Xtrain_normalized</span> <span class="o">=</span> <span class="n">poly_all</span><span class="p">(</span><span class="n">Xtrain_normalized</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">Xtrain_normalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">Xtrain_normalized</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span> <span class="n">Xtrain_normalized</span><span class="p">]</span>

<span class="n">Xvalsmall</span> <span class="o">=</span> <span class="n">selectFeatures</span><span class="p">(</span><span class="n">Xval</span><span class="p">)</span>
<span class="n">Xval_normalized</span> <span class="o">=</span> <span class="n">featureNormalizePredefined</span><span class="p">(</span><span class="n">Xvalsmall</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
<span class="n">Xval_normalized</span> <span class="o">=</span> <span class="n">poly_all</span><span class="p">(</span><span class="n">Xval_normalized</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">Xval_normalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">Xval_normalized</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span> <span class="n">Xval_normalized</span><span class="p">]</span>

<span class="c"># tuning parameters</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Xtrain_normalized</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">lambda_val</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="c"># training algo</span>
<span class="c">#lrTrain(iterations, theta, Xtrain_normalized, Ytrain, lambda_val, alpha)</span>

<span class="c">#learningCurve(Xtrain_normalized, Ytrain, Xval_normalized, Yval, lambda_val, iterations, theta, alpha)</span>

<span class="n">theta_pred</span> <span class="o">=</span> <span class="n">lrTrain</span><span class="p">(</span><span class="n">iterations</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">Xtrain_normalized</span><span class="p">,</span> <span class="n">Ytrain</span><span class="p">,</span> <span class="n">lambda_val</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>


<span class="n">Xtestsmall</span> <span class="o">=</span> <span class="n">selectFeatures</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
<span class="n">Xtest_normalized</span> <span class="o">=</span> <span class="n">featureNormalizePredefined</span><span class="p">(</span><span class="n">Xtestsmall</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
<span class="n">Xtest_normalized</span> <span class="o">=</span> <span class="n">poly_all</span><span class="p">(</span><span class="n">Xtest_normalized</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">Xtest_normalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">Xtest_normalized</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span> <span class="n">Xtest_normalized</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="n">lrCostFunctionCost</span><span class="p">(</span><span class="n">theta_pred</span><span class="p">,</span> <span class="n">Xtest_normalized</span><span class="p">,</span> <span class="n">Ytest</span><span class="p">,</span> <span class="n">lambda_val</span><span class="p">))</span>

</code></pre>
</div>

<p><img src="public/output_9_0.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>0.497460480159
0.325746064892
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># square root mean using basic gradient descent</span>

<span class="n">y_pred_lr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xtest_normalized</span><span class="p">,</span> <span class="n">theta_pred</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">getcost_srm</span><span class="p">(</span><span class="n">y_pred_lr</span><span class="p">,</span> <span class="n">Ytest</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>57.50217387195027
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># cross check with scikit-learn SVM </span>

<span class="n">x_svm</span> <span class="o">=</span> <span class="n">Xtrain_normalized</span>
<span class="n">y_svm</span> <span class="o">=</span> <span class="n">Ytrain</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">Ytrain</span><span class="p">),))</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s">'l2'</span><span class="p">,</span>
                        <span class="n">dual</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                        <span class="n">tol</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span>
                        <span class="n">C</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span>
                        <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                        <span class="n">intercept_scaling</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">class_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                        <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">solver</span><span class="o">=</span><span class="s">'newton-cg'</span><span class="p">,</span>
                        <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">multi_class</span><span class="o">=</span><span class="s">'multinomial'</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">warm_start</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_svm</span><span class="p">,</span> <span class="n">y_svm</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest_normalized</span><span class="p">)</span>

<span class="c"># calculating srm </span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">getcost_srm</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">Ytest</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>0.03253615118933862
</code></pre>
</div>


  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2017/02/20/chat-analysis-using-R/">
        Chat analysis
      </a>
    </h1>

    <span class="post-date">20 Feb 2017</span>

    <h1 id="chat-analysis-google-hangout-and-whatsapp">Chat analysis (google hangout and whatsapp)</h1>
<p>little experiment I did last year, using R NLP librarires and hangout and whatsapp data.</p>

<h3 id="github-link"><a href="https://github.com/ranuzz/chatAnalysis"><strong>GitHub Link</strong></a></h3>

<h3 id="gettingcleaning-hangout-data">Getting/Cleaning hangout data</h3>
<p>Hangout data can be downloaded using google takeaway. The data that I used and tested is from 2014-2015 timeframe.
JSON file provided by google is very huge and requires knowledge of data format to 
extract the conversation so I used https://bitbucket.org/dotcs/hangouts-log-reader/ tool to extract the convertion</p>

<p>after processing the output of ‘hangout_reader.py’ I had the file in this format:</p>

<blockquote>
  <p>2014-02-18 16:44:22: &lt;1author-1&gt; message <br />
2014-02-18 16:44:33: &lt;2author-2&gt; message</p>
</blockquote>

<h3 id="gettingcleaning-whatsapp-data">Getting/Cleaning whatsapp data</h3>
<p>Getting whatsapp data was straight forward. Just emailed the conversation to my inbox. only problem was that the format
slightyly changed in between 2014 and 2015. so I had to use two different parsing code.</p>

<p>2014 format</p>
<blockquote>
  <p>09:53, 21 Jan - 1author-1: message <br />
09:57, 24 Jan - 2author-2: message</p>
</blockquote>

<p>2015 format</p>
<blockquote>
  <p>20/05/2015, 1:18 PM - 1author-1: message <br />
20/05/2015, 1:18 PM - 2author-2: message</p>
</blockquote>

<h3 id="final-data-format">Final data format</h3>
<p>Final data was exported to individual CSV files <em>(cleanChat.c)</em> with following columns</p>
<ul>
  <li>year</li>
  <li>month</li>
  <li>day</li>
  <li>hour</li>
  <li>minute</li>
  <li>author</li>
  <li>message</li>
  <li>source</li>
</ul>

<h3 id="data-input">Data input</h3>
<p>datain.R : to input data</p>

<h3 id="wordcloud">WordCloud</h3>
<p>wordcloud.R : Generates a basic wordcloud
libraries</p>
<ul>
  <li>slam</li>
  <li>tm</li>
  <li>wordcloud</li>
</ul>

<h3 id="ggplot2">GGplot2</h3>
<p>ggplot2.R : Generates a basic graph
library</p>
<ul>
  <li>ggplot2</li>
</ul>

<h3 id="other-details">Other details</h3>
<p>R version : 3.2.5</p>

<h3 id="further-work">further work</h3>
<p>will add more experiments soon.</p>

  </div>
  
</div>

<div class="pagination">
  
    <span class="pagination-item older">Older</span>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
